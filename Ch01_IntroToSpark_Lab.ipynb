{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz5zGzS19FSM"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/student/ROI/Spark')\n",
    "from initspark import *\n",
    "sc, spark, conf = initspark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOnjzU-69FSP"
   },
   "source": [
    "LAB: Put the regions folder found in /home/student/ROI/SparkProgram/datasets/northwind/CSV/regions into HDFS. Read it into an RDD and convert it into a tuple shape. **This is a test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1Sdl9BG9FSQ"
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put /home/student/ROI/Spark/datasets/northwind/CSV/regions /regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPiYiVSb9FST",
    "outputId": "77edd26d-5523-4318-ba33-c5209074e74f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Eastern'), (2, 'Western'), (3, 'Northern'), (4, 'Southern')]\n"
     ]
    }
   ],
   "source": [
    "regions = sc.textFile('hdfs://localhost:9000/regions')\n",
    "regions = regions.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
    "print (regions.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ht10I0k49FSY"
   },
   "source": [
    "LAB: Try to sort region by name and descending order by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjlrIziN9FSY",
    "outputId": "2fdba060-280c-452f-b65f-e1099c76e6a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 'Southern'), (3, 'Northern'), (2, 'Western'), (1, 'Eastern')]\n"
     ]
    }
   ],
   "source": [
    "print (regions.sortByKey(ascending = False).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHPC3Z6P9FSc",
    "outputId": "e654c53a-10fc-4474-b7bb-a725611cfb47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Eastern'), (3, 'Northern'), (4, 'Southern'), (2, 'Western')]\n"
     ]
    }
   ],
   "source": [
    "print (regions.sortBy(lambda x : x[1]).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrB9sKyp9FSf"
   },
   "source": [
    "LAB: Load territories into HDFS and join it to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xj07HK3v9FSg"
   },
   "outputs": [],
   "source": [
    "! hadoop fs -put /home/student/ROI/Spark/datasets/northwind/CSV/territories /territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPDtcXt59FSk",
    "outputId": "2031d688-4a86-4135-d137-1b38e4f62814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1581, 'Westboro', 1), (1730, 'Bedford', 1), (1833, 'Georgetow', 1), (2116, 'Boston', 1), (2139, 'Cambridge', 1), (2184, 'Braintree', 1), (2903, 'Providence', 1), (3049, 'Hollis', 3), (3801, 'Portsmouth', 3), (6897, 'Wilton', 1), (7960, 'Morristown', 1), (8837, 'Edison', 1), (10019, 'New York', 1), (10038, 'New York', 1), (11747, 'Mellvile', 1), (14450, 'Fairport', 1), (19428, 'Philadelphia', 3), (19713, 'Neward', 1), (20852, 'Rockville', 1), (27403, 'Greensboro', 1), (27511, 'Cary', 1), (29202, 'Columbia', 4), (30346, 'Atlanta', 4), (31406, 'Savannah', 4), (32859, 'Orlando', 4), (33607, 'Tampa', 4), (40222, 'Louisville', 1), (44122, 'Beachwood', 3), (45839, 'Findlay', 3), (48075, 'Southfield', 3), (48084, 'Troy', 3), (48304, 'Bloomfield Hills', 3), (53404, 'Racine', 3), (55113, 'Roseville', 3), (55439, 'Minneapolis', 3), (60179, 'Hoffman Estates', 2), (60601, 'Chicago', 2), (72716, 'Bentonville', 4), (75234, 'Dallas', 4), (78759, 'Austin', 4), (80202, 'Denver', 2), (80909, 'Colorado Springs', 2), (85014, 'Phoenix', 2), (85251, 'Scottsdale', 2), (90405, 'Santa Monica', 2), (94025, 'Menlo Park', 2), (94105, 'San Francisco', 2), (95008, 'Campbell', 2), (95054, 'Santa Clara', 2), (95060, 'Santa Cruz', 2), (98004, 'Bellevue', 2), (98052, 'Redmond', 2), (98104, 'Seattle', 2)]\n"
     ]
    }
   ],
   "source": [
    "territories = sc.textFile('hdfs://localhost:9000/territories')\n",
    "territories = territories.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1], int(x[2])))\n",
    "print (territories.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkmZI_Cr9FSp"
   },
   "source": [
    "LAB: Use the territories RDD to count how many territories are in each region. Display the results in regionID order and then descending order based on the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47Uo0ZmD9FSr",
    "outputId": "65b8504e-4ac1-40d9-9fc5-8a5be0204e5b"
   },
   "outputs": [],
   "source": [
    "region_count = territories.map(lambda x : (x[2], 1)).reduceByKey(lambda x, y: x + y)\n",
    "print(region_count.sortByKey().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-w8uWom9FSx",
    "outputId": "9cbd708a-654a-41e1-e08b-1b787b3d6f43"
   },
   "outputs": [],
   "source": [
    "print(region_count.sortBy(lambda x : x[1], ascending = False).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAnAvET39FS0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day1Labs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
