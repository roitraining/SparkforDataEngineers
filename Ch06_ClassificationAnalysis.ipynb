{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/roitraining/SparkforDataEngineers/blob/Development/Ch06_ClassificationAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVESJgGmrOnE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "rootpath = '/home/student/ROI/Spark/'\n",
    "datapath = f'{rootpath}datasets/'\n",
    "sys.path.append(rootpath)\n",
    "import pyspark_helpers as pyh\n",
    "from pyspark_helpers import *\n",
    "sc, spark, conf = initspark()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pyspark_helpers import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read in a bank data set to try to predict if a potential borrower will default on their loan before lending to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xOtG6pXJrOnN"
   },
   "outputs": [],
   "source": [
    "filename = 'bank.csv'\n",
    "df = spark.read.csv(f'{datapath}/finance/{filename}', header = True, inferSchema = True)\n",
    "display(df)\n",
    "\n",
    "# Save a pointer to the raw data\n",
    "dfRawFile = df\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the dataset by identifying the numeric and categorical features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-FZqXtsrOnR"
   },
   "outputs": [],
   "source": [
    "# Let's just keep a few fields to start with for simplicity\n",
    "import imp\n",
    "imp.reload(pyh)\n",
    "\n",
    "num = pyh.auto_numeric_features(df, exceptlist = ('day'))\n",
    "print (num)\n",
    "cat = pyh.auto_categorical_features(df, suffix = None, exceptlist = ('default'))\n",
    "#cat = pyh.auto_categorical_features(df, suffix = ('ing', 'ion'))\n",
    "print (cat)\n",
    "\n",
    "numeric_features = ['age','balance', 'duration', 'pdays']\n",
    "categorical_features = ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'campaign', 'poutcome', 'deposit']\n",
    "\n",
    "# numeric_features = ['balance', 'duration', 'age']\n",
    "# categorical_features = ['marital', 'education']\n",
    "target_label = 'default'\n",
    "\n",
    "\n",
    "df = dfRawFile.select(numeric_features + categorical_features + [target_label])\n",
    "display(df)\n",
    "print(df.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27HGsZ6ArOnW"
   },
   "source": [
    "### Explore numeric features. To see if there is any correlation between values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMFO0oVOrOnY"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#display(df.describe())\n",
    "display(pyh.describe_numeric_features(df, numeric_features))\n",
    "pyh.scatter_matrix(df, numeric_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the helper function to reshape it for ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CtWabts7rOnc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import imp\n",
    "# imp.reload(pyh)\n",
    "\n",
    "dfML, keydict = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label = 'default', target_is_categorical=True, return_key_dict = True)\n",
    "display(dfML)\n",
    "dfML.printSchema()\n",
    "labelCnt = dfML.groupBy('label').count()\n",
    "display(labelCnt)\n",
    "print('keydict ' , keydict)\n",
    "print(dfML.take(1))\n",
    "print(df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xw_RBw9xrOnf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "labelCnt.toPandas().plot(kind = 'bar')\n",
    "df.groupBy('job').count().toPandas().plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Vectorized file in case we want to use it again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AevDiyFrOnp"
   },
   "outputs": [],
   "source": [
    "# dfML.write.format('parquet').mode('overwrite').save('testsave')\n",
    "# dfML0 = spark.read.format('parquet').load('testsave')\n",
    "# dfML0.printSchema()\n",
    "# display(dfML0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split it into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJ5WvSOErOnt"
   },
   "outputs": [],
   "source": [
    "#dfML = dfML0\n",
    "train, test = dfML.randomSplit([.7,.3], seed = 100)\n",
    "print (f'Training set row count {train.count()}')\n",
    "print (f'Testing set row count {test.count()}')\n",
    "display(train.groupBy('label').count())\n",
    "display(test.groupBy('label').count())\n",
    "#print(test.take(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Decision Tree classifier and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnOwIT8_rOnw"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 6)\n",
    "dtModel = dt.fit(train)\n",
    "print('DT Trained')\n",
    "\n",
    "filename1 = filename.replace('.','_') + '_DT_trainedModel'\n",
    "dtModel.write().overwrite().save(filename1)\n",
    "print('DT Saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dtModel.transform(test)\n",
    "display(pred)\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "metrics = MulticlassMetrics(pred.select(['label', 'prediction']).rdd.map(lambda line: (line[1], line[0])))\n",
    "print(metrics.confusionMatrix().toArray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally there are a lot of steps to predict and test. We have built a helper function to bundle all that up.\n",
    "Take a look at the source code for it to see those indivual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EByE2E-WrOn0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dtPredictions, dtLog = pyh.predict_and_evaluate(dtModel, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "rdd = df.rdd\n",
    "print(type(df), type(rdd))\n",
    "print(df.take(1))\n",
    "print(rdd.take(1))\n",
    "\n",
    "print(dir(df))\n",
    "print ('*' * 50)\n",
    "print(dir(rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goWOCubRrOn5"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)\n",
    "lrModel = lr.fit(train)\n",
    "print('LR Trained')\n",
    "\n",
    "filename1 = filename.replace('.','_') + '_LR_trainedModel'\n",
    "lrModel.write().overwrite().save(filename1)\n",
    "print('LR Saved')\n",
    "\n",
    "#evaluate_model(lr)\n",
    "pyh.beta_coefficients(lrModel)\n",
    "pyh.roc_curve(lrModel)\n",
    "pyh.precision_recall(lrModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normally you should be able to load the trained model, but for some reason it's not working correctly on this VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVPv5t1irOn9"
   },
   "outputs": [],
   "source": [
    "#lrModel2 = LogisticRegression.load(filename1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the test results as before, but LR has some extra options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGB_IDUUrOoB"
   },
   "outputs": [],
   "source": [
    "print(lrModel.summary.roc)\n",
    "lrPredictions, lrLog = pyh.predict_and_evaluate(lrModel, test, showModel = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try different thresholds to see if we can tweak the false positive/negative balance or improve the overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10, threshold = .1).fit(train)\n",
    "\n",
    "lr2Predictions, lr2Log = pyh.predict_and_evaluate(lr2, test, showModel = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "print(lr2Predictions.select('probability').take(2))\n",
    "#print(lr2Predictions.where('probability[0] >= .2 and probability <= .8').select('probability').take(2))\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "spark.udf.register('firstelement', lambda v:float(v[0]), FloatType())\n",
    "\n",
    "lr2Predictions.createOrReplaceTempView('predictions')\n",
    "display(spark.sql('select probability from predictions where firstelement(probability) between .2 and .8'))\n",
    "\n",
    "firstelement=udf(lambda v:float(v[0]),FloatType())\n",
    "#lr2Predictions.select(firstelement('probability')).show()\n",
    "lr2Predictions.where(firstelement('probability') >= .2).where(firstelement('probability') <= .8 ).select('probability').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After a while it's the same thing over and over, but try out as many models as possible to see which works best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XoN-fiT2rOoE"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label', numTrees = 10, maxDepth = 3)\n",
    "rfModel = rf.fit(train)\n",
    "print('RF Trained')\n",
    "\n",
    "filename1 = filename.replace('.','_') + '_RF_trainedModel'\n",
    "rfModel.write().overwrite().save(filename1)\n",
    "print('RF Saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aF0GSzKXrOoK"
   },
   "outputs": [],
   "source": [
    "rfPredictions, rfLog = pyh.predict_and_evaluate(rfModel, test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90o6tiojrOoO"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(train)\n",
    "print ('GBT Trained')\n",
    "\n",
    "filename1 = filename.replace('.','_') + '_GBT_trainedModel'\n",
    "rfModel.write().overwrite().save(filename1)\n",
    "print ('GBT Saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wuna45UTrOoR"
   },
   "outputs": [],
   "source": [
    "gbtPredictions, gbtLog = pyh.predict_and_evaluate(gbtModel, test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QPLoCu1rOoV"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 13 (features), two intermediate of size 5 and 4\n",
    "# and output of size 2 (classes)\n",
    "layers = [13, 5, 4, 2]\n",
    "\n",
    "nn = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "nnModel = nn.fit(train)\n",
    "print ('NN Trained')\n",
    "\n",
    "filename1 = filename.replace('.','_') + '_NN_trainedModel'\n",
    "nnModel.write().overwrite().save(filename1)\n",
    "print ('NN Saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnPredictions = nnModel.transform(test)\n",
    "#pyh.evaluate_ROC(nnPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blt7nlLJrOoe"
   },
   "outputs": [],
   "source": [
    "nnPredictions = nnModel.transform(test)\n",
    "print(type(nnPredictions))\n",
    "#print(nnPredictions.take(1))\n",
    "nnPredictions.printSchema()\n",
    "print (nnPredictions.count())\n",
    "\n",
    "nnPredictions, nnLog = pyh.predict_and_evaluate(nnModel, test)\n",
    "##nnPredictions.take(1)\n",
    "# predictionAndLabels = nnPredictions.select(\"prediction\", \"label\")\n",
    "# #display(predictionAndLabels)\n",
    "# print(predictionAndLabels.collect())\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "# print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EiZnj3adrOot",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "models = [\n",
    "    (DecisionTreeClassifier, dict(featuresCol = 'features', labelCol = 'label', maxDepth = 6))\n",
    "    , (DecisionTreeClassifier, dict(featuresCol = 'features', labelCol = 'label', maxDepth = 3))\n",
    "    , (MultilayerPerceptronClassifier, dict(maxIter=100, layers=[13, 5, 4, 2], blockSize=128, seed=1234))\n",
    "    , (MultilayerPerceptronClassifier, dict(maxIter=100, layers=[13, 3, 2], blockSize=128, seed=1234))\n",
    "    , (GBTClassifier, {})\n",
    "]\n",
    "\n",
    "for modelclass, params in models:\n",
    "    model = modelclass(**params)\n",
    "    trained = model.fit(train)\n",
    "    #pred = trained.transform(test)\n",
    "    pred, log = pyh.predict_and_evaluate(trained, test, showModel = False, show = False)\n",
    "    print (log)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Ch06_ClassificationAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
