{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Ch05_RegressionAnalysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roitraining/SparkforDataEngineers/blob/Development/Ch05_RegressionAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2_--H6q0C_",
        "colab_type": "text"
      },
      "source": [
        "### Initialize the spark environment and load the helper functions we have provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itiXd2lDq0DD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/home/student/ROI/SparkProgram')\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import numpy\n",
        "from matplotlib import pyplot as plt\n",
        "#from IPython.display import display\n",
        "\n",
        "import pyspark_helpers as pyh\n",
        "sc, spark, conf = pyh.initspark()\n",
        "from pyspark_helpers import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G73tQ_vxq0DJ",
        "colab_type": "text"
      },
      "source": [
        "### Read in a simple dataset of Boston Housing Prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppQVsqVLq0DL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filename = 'avocado.csv'\n",
        "#filename = 'HousingData.csv'\n",
        "filename = 'boston.csv'\n",
        "df = spark.read.csv(f'/home/student/ROI/Spark/datasets/finance/{filename}', header = True, inferSchema = True)\n",
        "display(df)\n",
        "df.printSchema()\n",
        "\n",
        "# Save a pointer to the raw data\n",
        "dfRaw = df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zm7_7wFq0DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "col = 'TOWN'\n",
        "indexer = StringIndexer(inputCol = col, outputCol = col+'_Index')\n",
        "x1 = indexer.fit(df).transform(df).select(col, col+'_Index').distinct()\n",
        "display(x1.orderBy(col))\n",
        "display(x1.orderBy(col+'_Index'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_7AYzbiq0DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x2 = pyh.StringIndexEncode(df, ['TOWN', 'TRACT'])\n",
        "display(x2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhilC-8Yq0DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col = 'TOWN'\n",
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "encoder = OneHotEncoderEstimator(inputCols=[col + '_Index'], outputCols=[col+'_Vector'])\n",
        "display(encoder.fit(x2).transform(x).orderBy(col + '_Index'))\n",
        "\n",
        "x = pyh.OneHotEncode(x2, ['TOWN', 'TRACT'])\n",
        "display (x)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAgDBLRwq0Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#sns.distplot(df.toPandas()['MEDV'])\n",
        "\n",
        "sns.distplot(df.where('MEDV < 48').toPandas()['MEDV'])\n",
        "print(df.columns)\n",
        "\n",
        "# If we want to filter out the outliers\n",
        "dfRaw = dfRaw.where('MEDV < 48')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDJ269zdq0De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if filename == 'avocado.csv':\n",
        "    df = dfRaw.withColumnRenamed('4046','PLU4046').withColumnRenamed('4225','PLU4225').withColumnRenamed('4770','PLU4770')\n",
        "    df.createOrReplaceTempView('dfRaw')\n",
        "    df.printSchema()\n",
        "\n",
        "    sql = '''select AveragePrice as target, `Total Volume` as totalvolume\n",
        "    , PLU4046, PLU4225, PLU4770\n",
        "    , `Small Bags` as smallbags, `Large Bags` as largebags, `XLarge Bags` as xlargebags\n",
        "    , type, year, region\n",
        "    FROM dfRaw'''\n",
        "\n",
        "    df = spark.sql(sql)\n",
        "    print(df)\n",
        "\n",
        "    numeric_features = ['totalvolume','PLU4046', 'PLU4225', 'PLU4770', 'smallbags', 'largebags', 'xlargebags']\n",
        "    categorical_features = ['type', 'year','region']\n",
        "    target_label = 'target'\n",
        "    print(df.take(1))\n",
        "else:\n",
        "    numeric_features = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO']\n",
        "    categorical_features = [] #['TOWN', 'TRACT']\n",
        "    target_label = 'MEDV'\n",
        "    df = dfRaw.select(categorical_features + numeric_features + [target_label])\n",
        "    df.printSchema()\n",
        "\n",
        "print ('******')\n",
        "display(df.describe())\n",
        "\n",
        "print ('******')\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egQIxlV9q0Di",
        "colab_type": "text"
      },
      "source": [
        "### Turn the dataframe into vectors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui-8gdQmq0Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import imp\n",
        "# imp.reload(pyh)\n",
        "\n",
        "# df10 = pyh.StringIndexEncode(df, categorical_features)\n",
        "# display(df10)\n",
        "# df11 = pyh.OneHotEncode(df10, categorical_features)\n",
        "# display(df11)\n",
        "# df12 = pyh.AssembleFeatures(df11, categorical_features, numeric_features, 'target', False)\n",
        "# display(df12)\n",
        "\n",
        "dfML = pyh.MakeMLDataFrame(df, categorical_features, numeric_features, target_label, False)\n",
        "display(dfML)\n",
        "dfML.printSchema()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaAFz43aq0Do",
        "colab_type": "text"
      },
      "source": [
        "### Split the dataset into train and test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E281O5cq0Dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = dfML.randomSplit([.7,.3], seed = 1000)\n",
        "print (f'Training set row count {train.count()}')\n",
        "print (f'Testing set row count {test.count()}')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHewcp-Kq0Dv",
        "colab_type": "text"
      },
      "source": [
        "### Run Linear Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7meyIk2q0Dw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol='target', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
        "lrModel = lr.fit(train)\n",
        "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
        "print(\"Intercept: \" + str(lrModel.intercept))\n",
        "\n",
        "print(\"Root Mean Squared Error: {}\\nR Squared (R2) {}\".format(lrModel.summary.rootMeanSquaredError, lrModel.summary.r2))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDuwpgTkq0Dz",
        "colab_type": "text"
      },
      "source": [
        "### Run test data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPWNhVvxq0D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lrPredictions = lrModel.transform(test)\n",
        "display(lrPredictions.select(\"prediction\",\"target\",\"features\"), 30)\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "lrEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\",metricName=\"r2\")\n",
        "testResult = lrModel.evaluate(test)\n",
        "print(\"Root Mean Squared Error on Test set: {}\".format(testResult.rootMeanSquaredError))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBJooYD3q0D5",
        "colab_type": "text"
      },
      "source": [
        "### Try Decision Tree Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCP7q5wdq0D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'target')\n",
        "dtModel = dt.fit(train)\n",
        "dtPredictions = dtModel.transform(test)\n",
        "important = dtModel.featureImportances\n",
        "print(type(important), important)\n",
        "#importantDict = zip(important[1], important[2])\n",
        "#print (importantDict)\n",
        "print (important[3])\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "dtEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\",metricName=\"rmse\")\n",
        "testResult = dtEvaluator.evaluate(dtPredictions)\n",
        "print(\"Root Mean Squared Error: {}\".format(testResult))\n",
        "dfML.take(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRwC0NLEq0D-",
        "colab_type": "text"
      },
      "source": [
        "### Try Gradient Boosted Tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmcJ4_trq0EA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'target', maxIter=10)\n",
        "gbtModel = gbt.fit(train)\n",
        "gbtPredictions = gbtModel.transform(test)\n",
        "display(gbtPredictions.select('prediction', 'target', 'features'), 20)\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "gbtEvaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"target\",metricName=\"rmse\")\n",
        "testResult = gbtEvaluator.evaluate(gbtPredictions)\n",
        "print(\"Root Mean Squared Error: {}\".format(testResult))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxEOP5ubq0EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}